{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f2325e",
   "metadata": {},
   "source": [
    "Q1>> What is Logistic Regression, and how does it differ from Linear Regression?\n",
    " \n",
    " --> Logistic Regression is a classification algorithm used to predict the probability of a binary outcome (e.g., Yes/No, 1/0, True/False). Unlike Linear Regression, which predicts continuous values, Logistic Regression outputs probabilities between 0 and 1 using the logistic function (sigmoid function).\n",
    " ### How Does It Differ from Linear Regression?\n",
    " Output Type:\n",
    "\n",
    "        Logistic Regression: Predicts probabilities (limited to 0-1).\n",
    "\n",
    "        Linear Regression: Predicts unbounded continuous values.\n",
    "\n",
    " Function Used:\n",
    "\n",
    "        Logistic Regression uses the sigmoid function to map predictions to probabilities.\n",
    "\n",
    "        Linear Regression uses a straight-line equation.\n",
    "\n",
    " Purpose:\n",
    "\n",
    "        Logistic Regression is for classification (e.g., \"Will the customer churn?\").\n",
    "\n",
    "        Linear Regression is for predicting quantities (e.g., \"What will the stock price be?\").\n",
    "\n",
    " Error Minimization:\n",
    "\n",
    "        Logistic Regression minimizes log-loss (penalizes wrong classifications).\n",
    "\n",
    "        Linear Regression minimizes MSE (penalizes distance from true value)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d208717",
   "metadata": {},
   "source": [
    "Q2>> What is the mathematical equation of Logistic Regression?\n",
    "\n",
    " --> Logistic Regression is a classification algorithm that predicts the probability of an outcome belonging to a particular class. The mathematical equation for Logistic Regression is:\n",
    "                                       \n",
    "                                       P(Y=1‚à£X)=œÉ(W^TX+b)\n",
    "  where:\n",
    "  \n",
    "    P(Y=1‚à£X) is the probability that the dependent variable Y equals 1 given the input features X.\n",
    "\n",
    "    X is the feature vector.\n",
    "\n",
    "    W is the weight vector (coefficients).\n",
    "\n",
    "    b is the bias term (intercept).\n",
    "\n",
    "    œÉ(z) is the sigmoid function, defined as:\n",
    "                            \n",
    "                            œÉ(z)= 1 / 1+e^‚àíz\n",
    " where \n",
    " \n",
    "     z=W^TX+b.\n",
    " #### Decision Rule\n",
    "The logistic regression model classifies inputs based on a threshold, typically 0.5:\n",
    "\n",
    "            ùëå= {1, ifP(Y = 1‚à£ùëã) ‚â• 0.5 and 0, if¬†ùëÉ(ùëå = 1‚à£ùëã) < 0.5\n",
    "            \n",
    "This makes Logistic Regression useful for binary classification problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc7aa39",
   "metadata": {},
   "source": [
    "Q3>> Why do we use the Sigmoid function in Logistic Regression?\n",
    "\n",
    " --> The sigmoid function (also called the logistic function) is fundamental to Logistic Regression because it solves a key problem: converting unbounded linear predictions into probabilities between 0 and 1. Here‚Äôs why it‚Äôs the perfect choice:\n",
    " ### Enables a Probabilistic Interpretation\n",
    "The output of Logistic Regression is not just a class label (0 or 1) but a probability score.\n",
    "\n",
    "If P(Y=1‚à£X) is greater than 0.5, we classify it as 1; otherwise, we classify it as 0.\n",
    "\n",
    " ### Differentiability for Optimization (Gradient Descent)\n",
    "The sigmoid function is smooth and differentiable everywhere, which allows us to use gradient descent to optimize the model by adjusting the weights.\n",
    " ### Non-Linearity for Decision Boundaries\n",
    "The sigmoid introduces a non-linearity, meaning it can model decision boundaries that aren‚Äôt purely linear.\n",
    "\n",
    "Although Logistic Regression is still a linear classifier in feature space, the sigmoid helps map inputs to probabilities in a non-linear way.\n",
    " ### Prevents Extreme Values (Exploding/Vanishing)\n",
    "Since sigmoid outputs values strictly between 0 and 1, it prevents the model from outputting extreme values that would be unrealistic probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43812037",
   "metadata": {},
   "source": [
    "Q4>> What is the cost function of Logistic Regression?\n",
    "\n",
    " --> The cost function for Logistic Regression is based on the concept of log-likelihood and is known as the Log Loss or Binary Cross-Entropy Loss.\n",
    " ### Why Use Log Loss?\n",
    "Convexity: The log loss function is convex, making it easier to optimize using gradient descent.\n",
    "\n",
    "Avoiding Large Errors: The logarithmic penalty prevents the model from making extremely wrong predictions. For example, if ùëåùëñ =1 but Y^i is close to 0, the loss is very high.\n",
    "\n",
    "Probabilistic Interpretation: Since logistic regression outputs probabilities, the log loss function naturally aligns with maximum likelihood estimation (MLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a61f55e",
   "metadata": {},
   "source": [
    "Q5>> What is Regularization in Logistic Regression? Why is it needed?\n",
    "\n",
    " --> Regularization is a technique used to prevent overfitting by adding a penalty term to the cost function. This penalty discourages the model from learning overly complex patterns that may not generalize well to unseen data.\n",
    " ### Why is Regularization Needed?\n",
    "Prevents Overfitting:\n",
    "\n",
    "        If the model has too many features, it might learn noise rather than true patterns.\n",
    "\n",
    "        Regularization prevents weights from becoming too large, ensuring a simpler model.\n",
    "\n",
    "Improves Generalization:\n",
    "\n",
    "        A model with large coefficients is sensitive to small variations in the input data.\n",
    "\n",
    "        Regularization keeps the model‚Äôs complexity in check, leading to better performance on unseen data.\n",
    "\n",
    "Reduces Multicollinearity:\n",
    "\n",
    "        In cases where independent variables are highly correlated, regularization helps distribute the weights more evenly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f568895",
   "metadata": {},
   "source": [
    "Q6>> Explain the difference between Lasso, Ridge, and Elastic Net regression.\n",
    "  \n",
    " -->Lasso, Ridge, and Elastic Net are all types of regularization techniques used to prevent overfitting by adding a penalty term to the cost function in regression models (including Logistic Regression and Linear Regression).\n",
    " ### Ridge Regression (L2 Regularization)\n",
    " Penalty Term:\n",
    "\n",
    "                ùúÜ ‚àë(ùëó=1 to n)ùëä^2ùëó\n",
    "                \n",
    "    Adds the sum of squared weights to the cost function.\n",
    "\n",
    "    Prevents large coefficients but does not force them to zero.\n",
    "  \n",
    " #### Key Features\n",
    " Prevents overfitting by keeping coefficients small.\n",
    " \n",
    " Works well when all features are useful (doesn‚Äôt remove any).\n",
    " \n",
    " Helps in handling multicollinearity (when predictors are highly correlated)\n",
    " #### Limitations\n",
    " Doesn‚Äôt perform feature selection since weights are only shrunk, not eliminated.\n",
    "\n",
    " May still have some unnecessary features affecting the model.\n",
    " ### Lasso Regression (L1 Regularization)\n",
    "     Adds the sum of absolute values of weights to the cost function.\n",
    "\n",
    "     Can force some weights to be exactly zero, effectively removing less important features.\n",
    "\n",
    " #### Key Features\n",
    " Feature selection: Lasso removes irrelevant features by setting their coefficients to zero.\n",
    "\n",
    " Leads to sparser models, making them interpretable and efficient.\n",
    "\n",
    " #### Limitations\n",
    " Can be unstable when features are highly correlated.\n",
    " \n",
    " May select only one feature among correlated ones and ignore others.\n",
    " \n",
    " ### Elastic Net Regression (L1 + L2 Regularization)\n",
    "     Combines both Lasso (L1) and Ridge (L2) regularization.\n",
    "\n",
    "     Keeps the benefits of both methods.\n",
    "\n",
    " #### Key Features\n",
    " Works well when features are highly correlated (avoids Lasso‚Äôs issue of selecting only one).\n",
    " \n",
    " Performs feature selection (like Lasso) but keeps some information (like Ridge).\n",
    "\n",
    " #### Limitations\n",
    " More computationally expensive since it involves tuning two hyperparameters: Œª1 and Œª2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc0f2ec",
   "metadata": {},
   "source": [
    "Q7>> When should we use Elastic Net instead of Lasso or Ridge?\n",
    "\n",
    " --> Elastic Net combines the benefits of Lasso (L1) and Ridge (L2), making it useful in certain situations where neither Lasso nor Ridge alone performs well.\n",
    " ### Use Elastic Net When:\n",
    " #### Features are Highly Correlated (Multicollinearity Exists)\n",
    "\n",
    "      Lasso tends to select only one feature from a group of correlated features and ignores the rest, which may lead \n",
    "          to information loss.\n",
    "\n",
    "      Elastic Net distributes weights more evenly among correlated features (like Ridge) but still performs feature \n",
    "       selection(like Lasso).\n",
    " #### You Want Feature Selection Without Losing Too Much Information\n",
    "\n",
    "      Lasso can shrink some coefficients completely to zero, removing certain features.\n",
    "\n",
    "      If this is too aggressive, Elastic Net partially shrinks weights instead of completely removing them.\n",
    " #### There Are More Features Than Observations (p >> n Problem)\n",
    "\n",
    "      In cases where the number of features p is much larger than the number of samples n, Lasso tends to select only a \n",
    "       few features, ignoring the rest.\n",
    "\n",
    "      Elastic Net ensures that some of those ignored features still contribute to the model while performing selection.\n",
    " #### When NOT to Use Elastic Net\n",
    "      If you don‚Äôt need feature selection, Ridge (L2) is a better choice.\n",
    "\n",
    "      If your features are independent (not correlated), Lasso (L1) alone may be sufficient.\n",
    " \n",
    "      If you only need to remove irrelevant features completely, Lasso is simpler and computationally cheaper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7453595",
   "metadata": {},
   "source": [
    "Q8>> What is the impact of the regularization parameter (Œª) in Logistic Regression?\n",
    "\n",
    " --> The regularization parameter (Œª) controls the strength of the penalty term in Logistic Regression. It determines how much we penalize large coefficients and helps balance the trade-off between bias and variance.\n",
    " ### Effect of Œª (Lambda) on the Model\n",
    " #### Large Œª (Strong Regularization)\n",
    "\n",
    "    Shrinks the weights (W) toward zero.\n",
    "\n",
    "    Reduces model complexity (simpler model).\n",
    "\n",
    "    Increases bias (underfitting).\n",
    "\n",
    "    Can ignore important features if Œª is too high.\n",
    "\n",
    " #### Small Œª (Weak Regularization)\n",
    "\n",
    "    Allows larger weights.\n",
    "\n",
    "    Increases model complexity (more flexibility).\n",
    "\n",
    "    Reduces bias, but increases variance (risk of overfitting).\n",
    " #### Œª = 0 (No Regularization)\n",
    "\n",
    "    The model behaves like standard Logistic Regression (maximum likelihood estimation).\n",
    "\n",
    "    No penalty on large coefficients.\n",
    "\n",
    "    High risk of overfitting, especially when features are highly correlated or the dataset has many features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1985f711",
   "metadata": {},
   "source": [
    "Q9>> What are the key assumptions of Logistic Regression?\n",
    "\n",
    " --> Although Logistic Regression is widely used for classification, it relies on several assumptions for optimal performance. Below are the key assumptions:\n",
    " ### The Dependent Variable is Binary (for Binary Logistic Regression)\n",
    "    Logistic Regression assumes that the target variable Y is binary (0 or 1).\n",
    "\n",
    "    For multiclass classification, a variant called Multinomial Logistic Regression is used.\n",
    " ### Independence of Observations\n",
    "    Each observation should be independent of the others.\n",
    "\n",
    "    If data points are correlated (e.g., time series data or hierarchical data), methods like Generalized Estimating \n",
    "      Equations (GEE) or Mixed Models should be used instead.\n",
    " ### No Perfect Multicollinearity\n",
    "    The independent variables should not be highly correlated with each other.\n",
    "\n",
    "    Multicollinearity can lead to unstable coefficient estimates.\n",
    "\n",
    "    Solution: Check for Variance Inflation Factor (VIF) and remove/merge correlated variables if needed.\n",
    " ### Linearity of Log-Odds (Logit Transformation)\n",
    "    Logistic Regression does not assume linearity between the independent variables and the dependent variable.\n",
    "    \n",
    "    Solution: If non-linearity exists, transform the variables (e.g., polynomial terms, splines) or use Non-Linear Models \n",
    "     like Decision Trees.\n",
    " ### Large Sample Size (Especially for Maximum Likelihood Estimation)\n",
    "    Logistic Regression works best with a sufficiently large dataset.\n",
    "\n",
    "    Small datasets may lead to unstable estimates.\n",
    " ### No Extreme Outliers\n",
    "    Logistic Regression is sensitive to outliers, which can distort the model.\n",
    "\n",
    "    Solution: Identify and remove outliers using techniques like IQR (Interquartile Range), Z-scores, or Winsorization.\n",
    " ### Independent Variables Should Not Have Too Many Missing Values\n",
    "    Missing values can lead to biased or unreliable models.\n",
    "\n",
    "    Solution: Use imputation methods (mean, median, KNN imputation) or remove observations with too many missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b092766",
   "metadata": {},
   "source": [
    "Q10>> What are some alternatives to Logistic Regression for classification tasks?\n",
    "\n",
    " -->While Logistic Regression is a powerful and interpretable model, there are several alternative algorithms that can be used for classification, depending on data complexity, feature interactions, and performance requirements.\n",
    "\n",
    " ### Decision Trees\n",
    " #### How It Works:\n",
    "\n",
    "    Splits data into smaller subsets based on feature values.\n",
    "\n",
    "    Forms a tree where each leaf node represents a class label.\n",
    "\n",
    " #### Pros:\n",
    "    Can model non-linear relationships.\n",
    "    \n",
    "    Easy to interpret and visualize.\n",
    "    \n",
    "    Handles missing values and irrelevant features well.\n",
    "\n",
    " #### Cons:\n",
    "    Prone to overfitting (solution: pruning or max depth restriction).\n",
    "\n",
    "    Sensitive to small changes in data.\n",
    " \n",
    " Best For: When relationships are non-linear and human interpretability is required\n",
    "    \n",
    " ### Random Forest\n",
    " #### How It Works:\n",
    "\n",
    "    An ensemble of multiple decision trees (Bagging technique).\n",
    "\n",
    "    Aggregates multiple tree predictions to improve accuracy.\n",
    "\n",
    " #### Pros:\n",
    "    Handles non-linearity better than Logistic Regression.\n",
    "    \n",
    "    Less prone to overfitting (due to averaging across trees).\n",
    "    \n",
    "    Works well with large datasets and many features.\n",
    "\n",
    " #### Cons:\n",
    "    Less interpretable than Logistic Regression or single decision trees.\n",
    "\n",
    "    Computationally expensive.\n",
    " \n",
    " Best For: High-dimensional data and cases where overfitting is a concern.\n",
    " ### Support Vector Machines (SVM)\n",
    " #### How It Works:\n",
    "\n",
    "    Finds the optimal hyperplane that separates classes with the maximum margin.\n",
    "\n",
    "    Uses kernels (e.g., RBF, polynomial) for non-linear classification.\n",
    "\n",
    " #### Pros:\n",
    "    Works well for high-dimensional data.\n",
    "\n",
    "    Effective for non-linearly separable data with kernel tricks.\n",
    "\n",
    "    Robust to outliers.\n",
    "\n",
    " #### Cons:\n",
    "    Computationally expensive for large datasets.\n",
    "    \n",
    "    Hard to tune hyperparameters (choosing the right kernel).\n",
    "\n",
    "  Best For: Small-to-medium datasets with complex boundaries.\n",
    " ### Na√Øve Bayes\n",
    " #### How It Works:\n",
    "\n",
    "    Uses Bayes‚Äô Theorem to estimate class probabilities assuming independence among features.\n",
    "\n",
    " #### Pros:\n",
    "    Fast and efficient, even with small datasets.\n",
    "    \n",
    "    Works well with text classification (e.g., spam detection).\n",
    "    \n",
    "    Handles missing data well.\n",
    "\n",
    " #### Cons:\n",
    "    Assumes feature independence, which is rarely true in real-world data.\n",
    "    \n",
    "    Less accurate when features are highly correlated.\n",
    "\n",
    " Best For: Text classification, spam filtering, and sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337f78bb",
   "metadata": {},
   "source": [
    "Q11>> What are Classification Evaluation Metrics?\n",
    "\n",
    " --> When evaluating a classification model, we need different metrics to measure its performance. The choice of metric depends on the problem type (binary, multi-class, or imbalanced data).\n",
    " ### Accuracy\n",
    " Formula:\n",
    " \n",
    "            Accuracy = Correct¬†Predictions / Total¬†Predictions\n",
    " #### Pros:\n",
    "    Simple and easy to interpret.\n",
    "    \n",
    "    Useful when classes are balanced.\n",
    "\n",
    " #### Cons:\n",
    "    Misleading for imbalanced datasets (e.g., 95% of data in one class ‚Üí accuracy is high but meaningless).\n",
    "\n",
    " Best For: Balanced datasets where all classes are equally important.\n",
    " ### Precision (Positive Predictive Value)\n",
    " Formula:\n",
    "\n",
    "            Precision = True¬†Positives / True¬†Positives + False¬†Positives\n",
    " \n",
    " #### Pros:\n",
    "    Important when False Positives (FP) are costly (e.g., medical diagnosis, spam filtering).\n",
    "\n",
    " #### Cons:\n",
    "    Ignores False Negatives (FN).\n",
    "\n",
    " Best For: When False Positives need to be minimized (e.g., cancer detection should avoid wrongly diagnosing a healthy patient).\n",
    " ### Recall (Sensitivity or True Positive Rate)\n",
    " Formula:\n",
    "\n",
    "            Recall = True¬†Positives / True¬†Positives + False¬†Negatives\n",
    "\n",
    " #### Pros:\n",
    "    Important when False Negatives (FN) are costly (e.g., detecting fraud, medical cases).\n",
    "\n",
    " #### Cons:\n",
    "    Ignores False Positives (FP).\n",
    "\n",
    " Best For: When missing positive cases is critical (e.g., detecting diseases, fraud detection).\n",
    "\n",
    " ### F1-Score (Harmonic Mean of Precision and Recall)\n",
    " Formula:\n",
    "\n",
    "            ùêπ1 = 2 √ó Precision √ó Recall / Precision + Recall\n",
    " \n",
    " #### Pros:\n",
    "    Balances Precision and Recall.\n",
    "    \n",
    "    Good for imbalanced datasets.\n",
    "\n",
    " #### Cons:\n",
    "    Hard to interpret compared to accuracy.\n",
    "\n",
    " Best For: When there‚Äôs an imbalance between classes and both Precision & Recall are important (e.g., fraud detection)\n",
    " ### Confusion Matrix\n",
    " #### Pros:\n",
    "    Shows detailed error analysis.\n",
    "\n",
    " #### Cons:\n",
    "    Hard to interpret for multi-class problems.\n",
    "\n",
    " Best For: Understanding where the model makes mistakes.\n",
    " ### ROC Curve (Receiver Operating Characteristic Curve)\n",
    " #### Definition:\n",
    "\n",
    "    Plots True Positive Rate (Recall) vs. False Positive Rate (1 - Specificity) at different thresholds.\n",
    "\n",
    "    Measures the model‚Äôs ability to distinguish between classes.\n",
    "\n",
    " #### Pros:\n",
    "    Useful for imbalanced data.\n",
    "    Shows trade-offs between sensitivity and specificity.\n",
    "\n",
    " Best For: Comparing multiple models‚Äô performance.\n",
    " ### AUC-ROC (Area Under the ROC Curve)\n",
    " #### Definition:\n",
    "\n",
    "    Measures the area under the ROC curve.\n",
    "\n",
    "    Values range from 0 to 1:\n",
    "\n",
    "        1.0 ‚Üí Perfect classifier\n",
    "\n",
    "        0.5 ‚Üí Random guess\n",
    "\n",
    "        < 0.5 ‚Üí Worse than random\n",
    "\n",
    " #### Pros:\n",
    "    Robust to class imbalance.\n",
    "\n",
    " Best For: When we need a single metric to compare models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456d1434",
   "metadata": {},
   "source": [
    "Q12>> How does class imbalance affect Logistic Regression?\n",
    "\n",
    " --> Class imbalance occurs when one class significantly outnumbers the other in a dataset. This can cause serious issues in Logistic Regression, leading to poor model performance.\n",
    " ### Problems Caused by Class Imbalance\n",
    " #### Biased Predictions Toward the Majority Class\n",
    "    Logistic Regression learns to maximize accuracy, so it tends to predict the majority class more often.\n",
    "\n",
    "    If 95% of the data is Class 0 and only 5% is Class 1, the model might always predict Class 0 and still achieve 95% \n",
    "     accuracy‚Äîbut it completely fails at identifying Class 1.\n",
    " #### Poor Precision, Recall, and F1-Score for the Minority Class\n",
    "    Recall (Sensitivity) for the minority class is low because the model fails to correctly identify positive cases.\n",
    "\n",
    "    Precision may also be poor because false positives can dominate.\n",
    "\n",
    "    F1-Score, which balances Precision and Recall, also suffers.\n",
    " ### Poor Probability Calibration\n",
    "    Logistic Regression outputs probabilities for predictions.\n",
    "\n",
    "    In imbalanced datasets, these probabilities can be poorly calibrated and biased toward the majority class.\n",
    "\n",
    "    The decision boundary may shift, making it harder to classify the minority class correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7b1670",
   "metadata": {},
   "source": [
    "Q13>> What is Hyperparameter Tuning in Logistic Regression?\n",
    "\n",
    " --> Hyperparameter tuning is the process of optimizing the settings (hyperparameters) of a Logistic Regression model to improve its performance.\n",
    " Unlike model parameters (like weights Œ∏), which are learned from data, hyperparameters are set before training and control how the model learns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231f9d1e",
   "metadata": {},
   "source": [
    "Q14>> What are different solvers in Logistic Regression? Which one should be used?\n",
    "\n",
    " --> In Logistic Regression, solvers are optimization algorithms used to find the best model coefficients (weights). Different solvers are optimized for different types of data, penalties, and performance trade-offs.\n",
    " ### Which Solver Should You Use?\n",
    " #### For small datasets:\n",
    "\n",
    "    Use liblinear (good for L1/L2 regularization).\n",
    "\n",
    " #### For large datasets (many features & observations):\n",
    "\n",
    "    Use lbfgs, newton-cg, or sag (faster convergence).\n",
    "\n",
    "    Use saga if L1 regularization is needed.\n",
    "\n",
    " #### For sparse data (many zeros in the dataset):\n",
    "    Use sag or saga (optimized for sparse matrices).\n",
    "\n",
    " #### For multiclass classification (multi_class='multinomial'):\n",
    "\n",
    "    Use lbfgs, newton-cg, sag, or saga (supports true multinomial logistic regression).\n",
    "\n",
    "    Avoid liblinear, as it only supports One-vs-Rest (OvR)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5299983c",
   "metadata": {},
   "source": [
    "Q15>> How is Logistic Regression extended for multiclass classification?\n",
    "\n",
    " --> By default, Logistic Regression is designed for binary classification (two classes). However, it can be extended for multiclass classification (three or more classes) using two main approaches:\n",
    " ### One-vs-Rest (OvR) [One-vs-All]\n",
    " #### How it works:\n",
    "\n",
    "    The model trains one classifier per class.\n",
    "\n",
    "    Each classifier treats one class as \"positive\" and all other classes as \"negative\".\n",
    "\n",
    "    During prediction, the class with the highest probability is chosen.\n",
    " ### Multinomial Logistic Regression (Softmax Regression)\n",
    " #### How it works:\n",
    "\n",
    "    Unlike OvR, only one classifier is trained.\n",
    "\n",
    "    Uses the softmax function to compute probabilities for all classes at once.\n",
    "\n",
    "    The model assigns the class with the highest probability.\n",
    "    \n",
    " Use multinomial with lbfgs when possible, as it is more efficient for large datasets.\n",
    " \n",
    " Use ovr with liblinear when using L1 regularization or working with small datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dfe06b",
   "metadata": {},
   "source": [
    "Q16>> What are the advantages and disadvantages of Logistic Regression?\n",
    "\n",
    " --> Advantages and disadvantages of Logistic Regression:\n",
    " ### Advantages\n",
    " ####  Simple & Easy to Implement:\n",
    "     Logistic Regression is straightforward and interpretable compared to complex models like Neural Networks.\n",
    " #### Fast Training & Prediction:\n",
    "     Training and inference are efficient, making it ideal for real-time applications.\n",
    " #### Works Well with Linearly Separable Data:\n",
    "     If the data is linearly separable, Logistic Regression can achieve high performance.\n",
    " #### Outputs Probabilities:\n",
    "     Unlike some classifiers, Logistic Regression provides probability estimates, useful for decision-making.\n",
    " #### Less Prone to Overfitting:\n",
    "     Regularization techniques (L1, L2, Elastic Net) help control overfitting.\n",
    " #### Robust to Small Datasets:\n",
    "     Unlike deep learning, Logistic Regression works well even with limited data.\n",
    " #### Feature Importance:\n",
    "     Coefficients give insights into the importance of each feature.\n",
    " ### Disadvantages\n",
    " #### Assumes Linearity:\n",
    "     Logistic Regression assumes a linear relationship between features and the log-odds. Fails for highly non-linear data.\n",
    " #### Struggles with Large Feature Spaces:\n",
    "     High-dimensional data can lead to overfitting unless regularization is applied.\n",
    " #### Sensitive to Outliers:\n",
    "     Outliers can skew predictions since Logistic Regression is based on linear regression.\n",
    " #### Poor Performance on Imbalanced Data:\n",
    "     If one class dominates, Logistic Regression tends to predict the majority class more often.\n",
    " #### Requires Feature Engineering:\n",
    "     Works best with hand-crafted features; may not automatically capture complex relationships like Decision Trees or\n",
    "       Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec8ab92",
   "metadata": {},
   "source": [
    "Q17>> What are some use cases of Logistic Regression?\n",
    "\n",
    " --> Logistic Regression is widely used in classification problems across various industries. Here are some key applications:\n",
    " ### Healthcare & Medical Diagnosis\n",
    " #### Disease Prediction & Diagnosis\n",
    "\n",
    "    Predicting diabetes, cancer, heart disease based on patient data.\n",
    "\n",
    "    Example: Logistic Regression classifies whether a tumor is malignant or benign.\n",
    "\n",
    " #### Medical Treatment Outcomes\n",
    "\n",
    "    Predicts whether a patient will respond to a treatment (Yes/No).\n",
    " ### Finance & Banking\n",
    " #### Credit Scoring & Loan Approval\n",
    "\n",
    "    Predicts if a customer will default on a loan based on income, credit history, etc.\n",
    "\n",
    " #### Fraud Detection\n",
    "\n",
    "    Classifies fraudulent vs. legitimate transactions.\n",
    " ### Marketing & Customer Analytics\n",
    " #### Customer Churn Prediction\n",
    "\n",
    "    Predicts whether a customer will cancel a subscription based on usage patterns.\n",
    "\n",
    " #### Ad Click Prediction\n",
    "\n",
    "    Predicts if a user will click on an online advertisement (Click-Through Rate).\n",
    " ### Education & Exam Performance\n",
    " #### Student Performance Prediction\n",
    "\n",
    "    Predicts if a student will pass/fail an exam based on study hours, attendance, and past performance.\n",
    "\n",
    " #### Dropout Prediction\n",
    "\n",
    "    Identifies students at risk of dropping out.\n",
    " ### Spam Detection & Sentiment Analysis\n",
    " #### Spam Email Classification\n",
    "\n",
    "    Predicts if an email is spam or not based on keywords and sender details.\n",
    "\n",
    " #### Sentiment Analysis\n",
    "\n",
    "    Classifies text as positive, negative, or neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f18d0ba",
   "metadata": {},
   "source": [
    "Q18>> What is the difference between Softmax Regression and Logistic Regression?\n",
    "\n",
    " --> Both Logistic Regression and Softmax Regression are classification algorithms, but they are used in different scenarios. Here's a breakdown of their differences:\n",
    " ### Logistic Regression\n",
    "    Used for: Binary Classification (Yes/No, 0/1, Spam/Not Spam)\n",
    "\n",
    "    Activation Function: Sigmoid\n",
    "\n",
    "    Output: A probability between 0 and 1\n",
    "\n",
    "    Decision Rule: Assigns the class with probability > 0.5\n",
    "    \n",
    "  Example:\n",
    "  \n",
    "    Predicting if an email is spam (1) or not spam (0).\n",
    " ### Softmax Regression (Multinomial Logistic Regression)\n",
    "    Used for: Multiclass Classification (3 or more classes)\n",
    "    \n",
    "    Activation Function: Softmax\n",
    "    \n",
    "    Output: A probability distribution across multiple classes\n",
    "    \n",
    "    Decision Rule: Assigns the class with the highest probability\n",
    "    \n",
    " Example:\n",
    " \n",
    "    Predicting if an image contains a cat (Class 1), dog (Class 2), or bird (Class 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b5261c",
   "metadata": {},
   "source": [
    "Q19>> How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?\n",
    "\n",
    " --> When using Logistic Regression for multiclass classification, we have two main strategies:\n",
    " \n",
    "    One-vs-Rest (OvR) (also called One-vs-All)\n",
    "    \n",
    "    Softmax Regression (also called Multinomial Logistic Regression)\n",
    " #### When to Use One-vs-Rest (OvR)?\n",
    "    When the dataset is small or when training time is not an issue.\n",
    "    \n",
    "    When using L1 regularization (OvR works with 'liblinear', while Softmax does not).\n",
    "    \n",
    "    When the classes are highly imbalanced.\n",
    "\n",
    " Example:\n",
    " \n",
    "    Predicting whether an image contains a cat, dog, or bird, where cat images are much more frequent.\n",
    " #### When to Use Softmax Regression?\n",
    "    When speed and efficiency are important (only one model is trained).\n",
    "    \n",
    "    When the number of classes is small to moderate (too many classes can make Softmax complex).\n",
    "    \n",
    "    When the classes are mutually exclusive and related (e.g., different types of animals, products, or emotions).\n",
    "\n",
    " Example:\n",
    " \n",
    "    Classifying handwritten digits (0-9) in MNIST dataset (digits have a natural ordering)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b81986",
   "metadata": {},
   "source": [
    "Q20>> How do we interpret coefficients in Logistic Regression?\n",
    "\n",
    " --> Unlike Linear Regression, where coefficients directly represent the change in output per unit change in a feature, Logistic Regression coefficients represent changes in log-odds. Here's how to interpret them:\n",
    " #### Understanding Logistic Regression Output\n",
    " #### Interpreting the Coefficients\n",
    "    Each coefficient Œ≤j represents the change in the log-odds of the outcome for a one-unit increase in feature Xj, keeping \n",
    "     all other variables constant.\n",
    " #### Handling Negative Coefficients\n",
    "    If a coefficient is negative, it means the feature decreases the likelihood of the positive outcome.\n",
    " #### Dealing with Categorical Variables\n",
    "    For categorical variables, Logistic Regression assigns one category as the baseline and calculates coefficients for \n",
    "     other categories relative to that baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc7dbad",
   "metadata": {},
   "source": [
    "# Practical Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3700744d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.80\n"
     ]
    }
   ],
   "source": [
    "#1> Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, \n",
    "#and prints the model accuracy.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load Dataset (Iris dataset as an example)\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "X = data.data  # Features\n",
    "y = (data.target == 1).astype(int)  # Binary classification (target=1 vs. rest)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f68525d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy with L1 Regularization: 0.77\n"
     ]
    }
   ],
   "source": [
    "#2> Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1')\n",
    "#and print the model accuracy.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load Dataset (Iris dataset as an example)\n",
    "data = load_iris()\n",
    "X = data.data  # Features\n",
    "y = (data.target == 1).astype(int)  # Convert to binary classification (target=1 vs. rest)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression Model with L1 Regularization (Lasso)\n",
    "model = LogisticRegression(penalty='l1', solver='liblinear', C=1.0)  # 'liblinear' supports L1\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy with L1 Regularization: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "583e8a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy with L2 Regularization: 0.80\n",
      "Model Coefficients (Œ≤): [[-0.03366829 -2.04408359  0.54273498 -1.01808515]]\n",
      "Intercept (Œ≤‚ÇÄ): [4.80897276]\n"
     ]
    }
   ],
   "source": [
    "#3> Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). \n",
    "#Print model accuracy and coefficients.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "#  Load Dataset (Iris dataset as an example)\n",
    "data = load_iris()\n",
    "X = data.data  # Features\n",
    "y = (data.target == 1).astype(int)  # Convert to binary classification (target=1 vs. rest)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression Model with L2 Regularization (Ridge)\n",
    "model = LogisticRegression(penalty='l2', solver='lbfgs', C=1.0)  # Default solver supports L2\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy with L2 Regularization: {accuracy:.2f}\")\n",
    "\n",
    "# Print Model Coefficients\n",
    "print(\"Model Coefficients (Œ≤):\", model.coef_)\n",
    "print(\"Intercept (Œ≤‚ÇÄ):\", model.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1acfe004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy with Elastic Net Regularization: 0.77\n",
      "Model Coefficients (Œ≤): [[ 0.47431904 -1.71181425  0.37376195 -0.98250351]]\n",
      "Intercept (Œ≤‚ÇÄ): [1.43652383]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#4> Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet').\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load Dataset (Iris dataset as an example)\n",
    "data = load_iris()\n",
    "X = data.data  # Features\n",
    "y = (data.target == 1).astype(int)  # Convert to binary classification (target=1 vs. rest)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression Model with Elastic Net Regularization\n",
    "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, C=1.0)  \n",
    "# l1_ratio=0.5 (50% L1, 50% L2)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy with Elastic Net Regularization: {accuracy:.2f}\")\n",
    "\n",
    "# Print Model Coefficients\n",
    "print(\"Model Coefficients (Œ≤):\", model.coef_)\n",
    "print(\"Intercept (Œ≤‚ÇÄ):\", model.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebc126d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy with One-vs-Rest (OvR): 1.00\n",
      "Model Coefficients (Œ≤): [[ 0.3711229   1.409712   -2.15210117 -0.95474179]\n",
      " [ 0.49400451 -1.58897112  0.43717015 -1.11187838]\n",
      " [-1.55895271 -1.58893375  2.39874554  2.15556209]]\n",
      "Intercept (Œ≤‚ÇÄ): [ 0.2478905   0.86408083 -1.00411267]\n"
     ]
    }
   ],
   "source": [
    "#5> Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load Dataset (Iris dataset - Multiclass Example)\n",
    "data = load_iris()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Multiclass target (0, 1, 2)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression Model with One-vs-Rest (OvR)\n",
    "model = LogisticRegression(multi_class='ovr', solver='liblinear')  \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy with One-vs-Rest (OvR): {accuracy:.2f}\")\n",
    "\n",
    "# Print Model Coefficients\n",
    "print(\"Model Coefficients (Œ≤):\", model.coef_)\n",
    "print(\"Intercept (Œ≤‚ÇÄ):\", model.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9069c785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Model Accuracy with Best Parameters: 1.00\n"
     ]
    }
   ],
   "source": [
    "#6> Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic \n",
    "#Regression. Print the best parameters and accuracy.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load Dataset (Iris dataset as an example)\n",
    "data = load_iris()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Multiclass target (0, 1, 2)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Hyperparameter Grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'penalty': ['l1', 'l2'],  # Regularization type\n",
    "    'solver': ['liblinear']  # 'liblinear' supports both L1 and L2\n",
    "}\n",
    "\n",
    "# Apply GridSearchCV for Hyperparameter Tuning\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get Best Parameters & Train Best Model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print Results\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Model Accuracy with Best Parameters: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "406d74dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracies: [0.96666667 1.         0.9        0.93333333 1.        ]\n",
      "Average Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "#7> Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load Dataset (Iris dataset as an example)\n",
    "data = load_iris()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Multiclass target (0, 1, 2)\n",
    "\n",
    "# Define Logistic Regression Model\n",
    "model = LogisticRegression(multi_class='ovr', solver='liblinear')\n",
    "\n",
    "# Set Up Stratified K-Fold Cross-Validation\n",
    "k = 5  # Number of folds\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform Cross-Validation\n",
    "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "# Print Average Accuracy\n",
    "print(f\"Cross-Validation Accuracies: {scores}\")\n",
    "print(f\"Average Accuracy: {np.mean(scores):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee4ba3b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Bajaj Pulsar AS200'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a469096dd5ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Train Logistic Regression Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# Make Predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1150\u001b[0m                 )\n\u001b[0;32m   1151\u001b[0m             ):\n\u001b[1;32m-> 1152\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1206\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1208\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m   1209\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1210\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 622\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    623\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1144\u001b[0m         )\n\u001b[0;32m   1145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1146\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m   1147\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1996\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1998\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1999\u001b[0m         if (\n\u001b[0;32m   2000\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Bajaj Pulsar AS200'"
     ]
    }
   ],
   "source": [
    "#8> Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load Dataset from CSV\n",
    "csv_file = \"BIKE DETAILS.csv\" \n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Define Features (X) and Target (y)\n",
    "target_column = \"selling_price\" \n",
    "X = df.drop(columns=[\"selling_price\"])  # Features\n",
    "y = df[\"selling_price\"]  # Target variable\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76bbd279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'solver': 'lbfgs', 'penalty': None, 'C': 2.154434690031882}\n",
      "Model Accuracy with Best Parameters: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "15 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1179, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1228, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1229, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.95833333 0.93333333 0.96666667 0.95833333\n",
      " 0.96666667        nan 0.95833333 0.96666667]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ayushi Jaiswal\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Q9> Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. \n",
    "#Print the best parameters and accuracy.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load Dataset (Iris dataset as an example)\n",
    "data = load_iris()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Multiclass target (0, 1, 2)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#  Define Hyperparameter Search Space\n",
    "param_dist = {\n",
    "    'C': np.logspace(-3, 3, 10),  # Regularization strength\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', None],  # Regularization types\n",
    "    'solver': ['liblinear', 'saga', 'lbfgs', 'newton-cg']  # Compatible solvers\n",
    "}\n",
    "\n",
    "#  Apply RandomizedSearchCV for Hyperparameter Tuning\n",
    "random_search = RandomizedSearchCV(\n",
    "    LogisticRegression(max_iter=5000), param_distributions=param_dist, \n",
    "    n_iter=10, cv=5, scoring='accuracy', random_state=42, n_jobs=-1\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get Best Parameters & Train Best Model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "#  Make Predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print Results\n",
    "print(f\"Best Hyperparameters: {random_search.best_params_}\")\n",
    "print(f\"Model Accuracy with Best Parameters: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62fca41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy with One-vs-One (OvO): 1.00\n"
     ]
    }
   ],
   "source": [
    "#Q10> Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load Dataset (Iris dataset as an example)\n",
    "data = load_iris()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Multiclass target (0, 1, 2)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression Model with One-vs-One (OvO)\n",
    "ovo_model = OneVsOneClassifier(LogisticRegression(solver='liblinear'))\n",
    "ovo_model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = ovo_model.predict(X_test)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#  Print Results\n",
    "print(f\"Model Accuracy with One-vs-One (OvO): {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d003a394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94        43\n",
      "           1       0.95      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Q11> Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load Dataset (Breast Cancer dataset as an example)\n",
    "data = load_breast_cancer()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Target (Binary: 0 or 1)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate Model Performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Compute Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize Confusion Matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c70586a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.95\n",
      "Recall: 0.99\n",
      "F1-Score: 0.97\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94        43\n",
      "           1       0.95      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q12> Write a Python program to train a Logistic Regression model and evaluate its performance using Precision,Recall, \n",
    "#and F1-Score.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load Dataset (Breast Cancer dataset as an example)\n",
    "data = load_breast_cancer()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Target (Binary: 0 or 1)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute Precision, Recall, and F1-Score\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print Evaluation Metrics\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "# Display Full Classification Report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "204590fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.95\n",
      "Recall: 0.99\n",
      "F1-Score: 0.97\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94        43\n",
      "           1       0.95      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q13> Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve \n",
    "#model performance\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load Dataset (Breast Cancer dataset as an example)\n",
    "data = load_breast_cancer()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Target (Binary: 0 or 1)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute Precision, Recall, and F1-Score\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print Evaluation Metrics\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "# Display Full Classification Report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2b57e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-d1072388a47b>:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['Age'] = imputer.fit_transform(X[['Age']])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d1072388a47b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mimputer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"most_frequent\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Fill missing values with most frequent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Embarked'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Embarked'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# Encode Categorical Variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3948\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3949\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3950\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3951\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3952\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4141\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4142\u001b[0m         \"\"\"\n\u001b[1;32m-> 4143\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4145\u001b[0m         if (\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4869\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4870\u001b[0m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4871\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4873\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    567\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m                 \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msubarr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Caller is responsible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1196\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "#Q14> Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate \n",
    "#performance.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load Titanic Dataset\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"  \n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Select Relevant Features & Target\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "target = 'Survived'\n",
    "\n",
    "# Extract features and target\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Handle Missing Values\n",
    "imputer = SimpleImputer(strategy=\"most_frequent\")  # Fill missing values with most frequent\n",
    "X['Age'] = imputer.fit_transform(X[['Age']])\n",
    "X['Embarked'] = imputer.fit_transform(X[['Embarked']])\n",
    "\n",
    "# Encode Categorical Variables\n",
    "X['Sex'] = LabelEncoder().fit_transform(X['Sex'])  # Convert 'Sex' (Male/Female) to 0/1\n",
    "X = pd.get_dummies(X, columns=['Embarked'], drop_first=True)  # One-hot encode 'Embarked'\n",
    "\n",
    "# Normalize Numerical Features\n",
    "scaler = StandardScaler()\n",
    "X[['Age', 'Fare']] = scaler.fit_transform(X[['Age', 'Fare']])\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate Model Performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7630294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Without Scaling: 0.96\n",
      "Accuracy With Scaling: 0.97\n"
     ]
    }
   ],
   "source": [
    "#Q15> Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. \n",
    "#Evaluate its accuracy and compare results with and without scaling\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load Dataset (Breast Cancer dataset as an example)\n",
    "data = load_breast_cancer()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Target (Binary Classification: 0 or 1)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression Without Scaling\n",
    "model_no_scaling = LogisticRegression(max_iter=5000)\n",
    "model_no_scaling.fit(X_train, y_train)\n",
    "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
    "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
    "\n",
    "# Apply Feature Scaling (Standardization)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression With Scaling\n",
    "model_scaled = LogisticRegression(max_iter=5000)\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
    "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
    "\n",
    "# Print Accuracy Results\n",
    "print(f\"Accuracy Without Scaling: {accuracy_no_scaling:.2f}\")\n",
    "print(f\"Accuracy With Scaling: {accuracy_scaled:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ce0964e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Score: 1.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Q16> Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load Dataset (Breast Cancer dataset as an example)\n",
    "data = load_breast_cancer()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Target (Binary: 0 or 1)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get Predicted Probabilities\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class (1)\n",
    "\n",
    "# Compute ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Compute ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Random guess line\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be39ab59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy with C=0.5: 0.96\n"
     ]
    }
   ],
   "source": [
    "#Q17> Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load Dataset (Breast Cancer dataset as an example)\n",
    "data = load_breast_cancer()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Target (Binary Classification: 0 or 1)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression Model with C=0.5\n",
    "model = LogisticRegression(C=0.5, solver='liblinear')  # Custom inverse regularization strength\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate Model Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy with C=0.5: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13e47cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Most Important Features:\n",
      "                 Feature  Coefficient  Absolute Coefficient\n",
      "0            mean radius     2.043540              2.043540\n",
      "26       worst concavity    -1.555718              1.555718\n",
      "11         texture error     1.434455              1.434455\n",
      "20          worst radius     1.209425              1.209425\n",
      "25     worst compactness    -1.183585              1.183585\n",
      "28        worst symmetry    -0.697654              0.697654\n",
      "6         mean concavity    -0.618553              0.618553\n",
      "27  worst concave points    -0.578440              0.578440\n",
      "5       mean compactness    -0.401738              0.401738\n",
      "21         worst texture    -0.399652              0.399652\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Q18> Write a Python program to train Logistic Regression and identify important features based on model coefficients.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load Dataset (Breast Cancer dataset as an example)\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)  # Convert to DataFrame for feature names\n",
    "y = data.target  # Target (Binary Classification: 0 or 1)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Extract Feature Importance (Coefficients)\n",
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Coefficient': model.coef_[0]})\n",
    "feature_importance['Absolute Coefficient'] = feature_importance['Coefficient'].abs()\n",
    "feature_importance = feature_importance.sort_values(by='Absolute Coefficient', ascending=False)\n",
    "\n",
    "# Display Top Features\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Plot Feature Importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['Feature'][:10], feature_importance['Absolute Coefficient'][:10], color='blue')\n",
    "plt.xlabel('Absolute Coefficient Value')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Top 10 Most Important Features in Logistic Regression')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for better visualization\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24fd9b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "Cohen‚Äôs Kappa Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "#Q19> Write a Python program to train Logistic Regression and evaluate its performance using Cohen‚Äôs Kappa Score.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load Dataset (Breast Cancer dataset as an example)\n",
    "data = load_breast_cancer()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Target (Binary Classification: 0 or 1)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate Model using Cohen‚Äôs Kappa Score\n",
    "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print Evaluation Metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Cohen‚Äôs Kappa Score: {kappa_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48b2a3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Q20> Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, auc, average_precision_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load Dataset (Breast Cancer dataset as an example)\n",
    "data = load_breast_cancer()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Target (Binary Classification: 0 or 1)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get Predicted Probabilities\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class (1)\n",
    "\n",
    "# Compute Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "average_precision = average_precision_score(y_test, y_prob)\n",
    "\n",
    "# Plot Precision-Recall Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, color='blue', label=f'PR Curve (AP = {average_precision:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08de8be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver: liblinear - Accuracy: 0.96\n",
      "Solver: saga - Accuracy: 0.97\n",
      "Solver: lbfgs - Accuracy: 0.96\n",
      "\n",
      "Comparison of Logistic Regression Solvers:\n",
      "liblinear: 0.96\n",
      "saga: 0.97\n",
      "lbfgs: 0.96\n"
     ]
    }
   ],
   "source": [
    "#Q21> Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their \n",
    "#accuracy.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load Dataset (Breast Cancer dataset as an example)\n",
    "data = load_breast_cancer()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Target (Binary Classification: 0 or 1)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Solvers to Compare\n",
    "solvers = ['liblinear', 'saga', 'lbfgs']\n",
    "accuracy_results = {}\n",
    "\n",
    "# Train Logistic Regression Model with Different Solvers\n",
    "for solver in solvers:\n",
    "    model = LogisticRegression(solver=solver, max_iter=5000)  # Increased max_iter for convergence\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_results[solver] = accuracy\n",
    "    print(f\"Solver: {solver} - Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Display Solver Accuracy Results\n",
    "print(\"\\nComparison of Logistic Regression Solvers:\")\n",
    "for solver, acc in accuracy_results.items():\n",
    "    print(f\"{solver}: {acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c13d40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "Matthews Correlation Coefficient (MCC): 0.91\n"
     ]
    }
   ],
   "source": [
    "#Q22> Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation \n",
    "#Coefficient (MCC).\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load Dataset (Breast Cancer dataset as an example)\n",
    "data = load_breast_cancer()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Target (Binary Classification: 0 or 1)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate Model using MCC\n",
    "mcc_score = matthews_corrcoef(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print Evaluation Metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Matthews Correlation Coefficient (MCC): {mcc_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be82279a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on RAW data: 0.96\n",
      "Accuracy on STANDARDIZED data: 0.97\n",
      "\n",
      "‚úÖ Standardization improved the model's performance!\n"
     ]
    }
   ],
   "source": [
    "#Q23>  Write a Python program to train Logistic Regression on both raw and standardized data. Compare their \n",
    "#accuracy to see the impact of feature scaling.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load Dataset (Breast Cancer dataset as an example)\n",
    "data = load_breast_cancer()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Target (Binary Classification: 0 or 1)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression on RAW Data\n",
    "model_raw = LogisticRegression(solver='liblinear')\n",
    "model_raw.fit(X_train, y_train)\n",
    "y_pred_raw = model_raw.predict(X_test)\n",
    "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
    "\n",
    "# Standardize the Data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression on STANDARDIZED Data\n",
    "model_scaled = LogisticRegression(solver='liblinear')\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
    "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
    "\n",
    "# Print Accuracy Comparison\n",
    "print(f\"Accuracy on RAW data: {accuracy_raw:.2f}\")\n",
    "print(f\"Accuracy on STANDARDIZED data: {accuracy_scaled:.2f}\")\n",
    "\n",
    "# Conclusion\n",
    "if accuracy_scaled > accuracy_raw:\n",
    "    print(\"\\n‚úÖ Standardization improved the model's performance!\")\n",
    "elif accuracy_scaled < accuracy_raw:\n",
    "    print(\"\\n‚ö†Ô∏è Standardization reduced accuracy, consider checking the dataset.\")\n",
    "else:\n",
    "    print(\"\\nüîç No change in accuracy, but standardization may help optimization.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92a47e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal C value: 10.000\n",
      "Test Accuracy with Optimal C: 0.96\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Q24> Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using\n",
    "#cross-validation.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load Dataset (Breast Cancer dataset as an example)\n",
    "data = load_breast_cancer()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Target (Binary Classification: 0 or 1)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Range of C values (Regularization Strength)\n",
    "C_values = np.logspace(-3, 3, 10)  # 10 values from 0.001 to 1000\n",
    "mean_cv_scores = []  # To store cross-validation scores\n",
    "\n",
    "# Perform Cross-Validation for Each C Value\n",
    "for C in C_values:\n",
    "    model = LogisticRegression(C=C, solver='liblinear')  # Using liblinear solver for small dataset\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')  # 5-Fold Cross-Validation\n",
    "    mean_cv_scores.append(scores.mean())  # Store mean accuracy\n",
    "\n",
    "# Find Optimal C\n",
    "optimal_C = C_values[np.argmax(mean_cv_scores)]\n",
    "print(f\"Optimal C value: {optimal_C:.3f}\")\n",
    "\n",
    "# Train Model with Optimal C and Evaluate on Test Data\n",
    "best_model = LogisticRegression(C=optimal_C, solver='liblinear')\n",
    "best_model.fit(X_train, y_train)\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Test Accuracy with Optimal C: {test_accuracy:.2f}\")\n",
    "\n",
    "# Plot Cross-Validation Accuracy vs. C Values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.semilogx(C_values, mean_cv_scores, marker='o', linestyle='dashed', color='blue')\n",
    "plt.xlabel('C (Regularization Strength)')\n",
    "plt.ylabel('Cross-Validation Accuracy')\n",
    "plt.title('Optimal C Value for Logistic Regression')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d41bc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved successfully as 'logistic_regression_model.pkl'\n",
      "üîÑ Model loaded successfully!\n",
      "üéØ Accuracy of Loaded Model: 0.96\n"
     ]
    }
   ],
   "source": [
    "#Q25> Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to\n",
    "#make predictions.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib  # For saving and loading the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load Dataset (Breast Cancer dataset as an example)\n",
    "data = load_breast_cancer()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Target (Binary Classification: 0 or 1)\n",
    "\n",
    "# Split Data into Training & Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save Trained Model to a File\n",
    "joblib.dump(model, \"logistic_regression_model.pkl\")\n",
    "print(\"‚úÖ Model saved successfully as 'logistic_regression_model.pkl'\")\n",
    "\n",
    "# Load the Model from the File\n",
    "loaded_model = joblib.load(\"logistic_regression_model.pkl\")\n",
    "print(\"üîÑ Model loaded successfully!\")\n",
    "\n",
    "# Make Predictions with the Loaded Model\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# Evaluate Model Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"üéØ Accuracy of Loaded Model: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e1ef20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
